{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "COVID_mental_health.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpLl7-Yn6B0m"
      },
      "source": [
        "##Multi-class Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDa3gzMCle6K",
        "outputId": "732c60f8-651f-4d37-eb48-20e0b20930b8"
      },
      "source": [
        "import os, sys, re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import (train_test_split,KFold)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the csv file and fill Nan/empty values as 0\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/pulse2020_puf_16.csv')\n",
        "#dataset = pd.read_csv('pulse2020_puf_16.csv')\n",
        "df = dataset.fillna(0)\n",
        "\n",
        "new_df = []\n",
        "new_df = pd.DataFrame(new_df) #Filtered dataset\n",
        "\n",
        "#Adding features to filtered dataset\n",
        "new_df['TBIRTH_YEAR'] = df['TBIRTH_YEAR']\n",
        "new_df['RHISPANIC'] = df['RHISPANIC']\n",
        "new_df['RRACE'] = df['RRACE']\n",
        "new_df['WRKLOSS'] = df['WRKLOSS']\n",
        "new_df['EGENDER'] = df['EGENDER']\n",
        "new_df['EEDUC'] = df['EEDUC']\n",
        "new_df['ANYWORK'] = df['ANYWORK']\n",
        "new_df['INCOME'] = df['INCOME']\n",
        "new_df['PRESCRIPT'] = df['PRESCRIPT']\n",
        "new_df['MH_SVCS'] = df['MH_SVCS']\n",
        "new_df['MH_NOTGET'] = df['MH_NOTGET']\n",
        "new_df['PWEIGHT'] = df['PWEIGHT']\n",
        "new_df['TENURE'] = df['TENURE']\n",
        "new_df['MORTCUR'] = df['MORTCUR']\n",
        "\n",
        "#Adding Target variables\n",
        "\n",
        "#new_df['ANXIOUS'] = df['ANXIOUS']\n",
        "#new_df['WORRY'] = df['WORRY']\n",
        "new_df['INTEREST'] = df['INTEREST']\n",
        "#new_df['DOWN'] = df['DOWN']\n",
        "\n",
        "#Dropping columns with missing data\n",
        "X = new_df\n",
        "l = new_df.columns\n",
        "for i in l:\n",
        "    indexNames = X[ X[i] == -88].index\n",
        "    # Delete these row indexes from dataFrame\n",
        "    X.drop(indexNames , inplace=True)\n",
        "\n",
        "indexNames = X[ X['INTEREST'] == -99].index  #if target is -99 then drop that row\n",
        "X.drop(indexNames , inplace=True)\n",
        "\n",
        "\n",
        "features = [['TBIRTH_YEAR', 'RHISPANIC', 'RRACE', 'WRKLOSS', 'EGENDER', 'EEDUC', 'ANYWORK', 'INCOME', 'PRESCRIPT', \n",
        "             'MH_SVCS', 'MH_NOTGET', 'PWEIGHT', 'TENURE', 'MORTCUR']]\n",
        "\n",
        "#Set Target and features\n",
        "y = X['INTEREST'].values\n",
        "X = X.drop(['INTEREST'], axis = 1)\n",
        "X.head()\n",
        "print(X.shape)\n",
        "#Split training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state=30)\n",
        "\n",
        "#Scaling for feature selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Feature Selection\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=12)\n",
        "X_train=pca.fit_transform(X_train)\n",
        "X_test=pca.transform(X_test)\n",
        "\n",
        "# kbest = SelectKBest(chi2, k=12)\n",
        "# X_train=kbest.fit_transform(X_train,y_train)\n",
        "# X_test=kbest.transform(X_test)\n",
        "\n",
        "#Imputation\n",
        "from sklearn.impute import KNNImputer,SimpleImputer\n",
        "imp7 = KNNImputer(missing_values=-88)\n",
        "X_train=pd.DataFrame(imp7.fit_transform(X_train))\n",
        "X_test=pd.DataFrame(imp7.transform(X_test))\n",
        "\n",
        "#Variance Plot\n",
        "#sns.set_theme(style=\"ticks\", color_codes=True)\n",
        "# percent_variance = np.round(pca.explained_variance_ratio_* 100, decimals =2)\n",
        "# plt.bar(x= range(1,11),height=percent_variance)\n",
        "# plt.ylabel('Percentate of Variance Explained')\n",
        "# plt.xlabel('Principal Component')\n",
        "# plt.show()\n",
        "\n",
        "#Classifiers\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred4=model.predict(X_test)\n",
        "print(\"XGboost \",metrics.classification_report(y_test,y_pred4))\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
        "adb=AdaBoostClassifier()\n",
        "adb.fit(X_train,y_train)\n",
        "y_pred3=adb.predict(X_test)\n",
        "print(\"Adaboost \",metrics.classification_report(y_test,y_pred3))\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1,max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"MLP\",metrics.classification_report(y_test,y_pred))\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(learning_rate=0.1, n_estimators=500)\n",
        "gb_clf.fit(X_train,y_train)\n",
        "y_pred2=gb_clf.predict(X_test)\n",
        "print(\"Gradient boost \",metrics.classification_report(y_test,y_pred2))\n",
        "\n",
        "rfc=RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "y_pred=rfc.predict(X_test)\n",
        "print(\"Random Forest \",metrics.classification_report(y_test,y_pred))\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svc=SVC()\n",
        "svc.fit(X_train,y_train)\n",
        "y_pred6=svc.predict(X_test)\n",
        "print(\"Svc \",metrics.classification_report(y_test,y_pred6))\n",
        "\n",
        "#Confusion matrix for the best performing classifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred4)\n",
        "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
        "            fmt='.2%', cmap='BuPu',xticklabels=[1,2,3,4],yticklabels=[1,2,3,4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38161, 14)\n",
            "(28620, 14) (28620,) (9541, 14) (9541,)\n",
            "XGboost  0.5687034902001886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoN8l3ZV59Y6"
      },
      "source": [
        "##Binary Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpttwbvAqwjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "d00b7475-cbe0-4d0d-a1fa-6b5ca93ce78d"
      },
      "source": [
        "import os, sys, re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import (train_test_split,KFold)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# import the dataset \n",
        "# Load the csv file and fill Nan/empty values as 0\n",
        "#dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/pulse2020_puf_16.csv')\n",
        "#dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/pulse2020_puf_15.csv')\n",
        "dataset = pd.read_csv('pulse2020_puf_16.csv')\n",
        "#dataset2 = pd.read_csv('pulse2020_puf_15.csv')\n",
        "\n",
        "df = dataset.fillna(0)\n",
        "# select the target variable\n",
        "target = 'DOWN'\n",
        "\n",
        "# new data frame with manually selected features\n",
        "new_df = []\n",
        "new_df = pd.DataFrame(new_df)\n",
        "new_df['TBIRTH_YEAR'] = df['TBIRTH_YEAR']\n",
        "new_df['RHISPANIC'] = df['RHISPANIC']\n",
        "new_df['RRACE'] = df['RRACE']\n",
        "new_df['WRKLOSS'] = df['WRKLOSS']\n",
        "new_df['EGENDER'] = df['EGENDER']\n",
        "new_df['EEDUC'] = df['EEDUC']\n",
        "new_df['ANYWORK'] = df['ANYWORK']\n",
        "new_df['INCOME'] = df['INCOME']\n",
        "#new_df['ANXIOUS'] = df['ANXIOUS']      # one of the target variable\n",
        "#new_df['WORRY'] = df['WORRY']          # one of the target variable\n",
        "#new_df['INTEREST'] = df['INTEREST']    # one of the target variable\n",
        "#new_df['DOWN'] = df['DOWN']            #target variable\n",
        "new_df[target] = df[target]\n",
        "new_df['PRESCRIPT'] = df['PRESCRIPT']\n",
        "new_df['MH_SVCS'] = df['MH_SVCS']\n",
        "new_df['MH_NOTGET'] = df['MH_NOTGET']\n",
        "new_df['PWEIGHT'] = df['PWEIGHT']\n",
        "new_df['TENURE'] = df['TENURE']\n",
        "new_df['MORTCUR'] = df['MORTCUR']\n",
        "\n",
        "result = new_df\n",
        "\n",
        "X = result\n",
        "\n",
        "# uncomment when dropping rows\n",
        "# l = result.columns\n",
        "\n",
        "\n",
        "# dropping -88 rows\n",
        "# for i in l:     \n",
        "#     indexNames = X[ X[i] == -88].index\n",
        "#     # Delete these row indexes from dataFrame\n",
        "#     X.drop(indexNames , inplace=True)\n",
        "\n",
        "# dropping -99 rows\n",
        "# for i in l:\n",
        "#     indexNames = X[ X[i] == -99].index\n",
        "#     # Delete these row indexes from dataFrame\n",
        "#     X.drop(indexNames , inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "indexNames = X[ X[target] == -99].index  #if anxious is -99 then drop that row\n",
        "X.drop(indexNames , inplace=True)\n",
        "\n",
        "\n",
        "# convert to binary classification\n",
        "X[target] = X[target].replace([1,2],0)\n",
        "X[target] = X[target].replace([3,4],1)\n",
        "\n",
        "y = X[target].values\n",
        "X = X.drop([target], axis = 1)\n",
        "# print(y)\n",
        "\n",
        "# import seaborn as sn\n",
        "# corrMatrix = X.corr()\n",
        "# plt.figure(figsize=(15,15))\n",
        "# sn.heatmap(corrMatrix, annot=True)\n",
        "# plt.show()\n",
        "\n",
        "print(X.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state=42)\n",
        "\n",
        "# imputation\n",
        "from sklearn.impute import KNNImputer,SimpleImputer\n",
        "imp7 = KNNImputer(missing_values=-88)\n",
        "X_train=pd.DataFrame(imp7.fit_transform(X_train))\n",
        "X_test=pd.DataFrame(imp7.transform(X_test))\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "# scaling of the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# perform pca for the features\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=14)\n",
        "# X_train=pca.fit_transform(X_train)\n",
        "# X_test=pca.transform(X_test)\n",
        "\n",
        "# select kbest features\n",
        "# Kbest = SelectKBest(chi2, k=12)\n",
        "# X_train=Kbest.fit_transform(X_train,y_train)\n",
        "# X_test=Kbest.transform(X_test)\n",
        "\n",
        "#print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "#sns.set_theme(style=\"ticks\", color_codes=True)\n",
        "#sns.barplot(x='INCOME',y='ANXIOUS',  data=new_df)\n",
        "#sns.stripplot(x='EEDUC',y='ANXIOUS',  data=new_df)\n",
        "#sns.barplot(x='EGENDER',y='ANXIOUS',  data=new_df)\n",
        "\n",
        "\n",
        "# MLP Classifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1,max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"MLP\",metrics.accuracy_score(y_test,y_pred))\n",
        "\n",
        "# Gradient Boost Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
        "gb_clf = GradientBoostingClassifier(learning_rate=0.1, n_estimators=500)\n",
        "gb_clf.fit(X_train,y_train)\n",
        "y_pred2=gb_clf.predict(X_test)\n",
        "print(\"Gradient boost with PCA/n\",metrics.accuracy_score(y_test,y_pred2))\n",
        "\n",
        "# Random Forest Classifier\n",
        "rfc=RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "y_pred=rfc.predict(X_test)\n",
        "print(\"Random Forest with PCA\",metrics.accuracy_score(y_test,y_pred))\n",
        "\n",
        "# AdaBoost Classifier\n",
        "adb=AdaBoostClassifier()\n",
        "adb.fit(X_train,y_train)\n",
        "y_pred3=adb.predict(X_test)\n",
        "print(\"Adaboost with PCA/n\",metrics.accuracy_score(y_test,y_pred3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0 -88   0 ...   0 -88   1]\n",
            "(94990, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-923be2404a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSimpleImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mimp7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             reduce_func=process_chunk)\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;31m# process_chunk modifies X in place. No return value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1595\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1596\u001b[0m         if ((X is Y or Y is None)\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# avoid divide by zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpresent_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mpresent_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}